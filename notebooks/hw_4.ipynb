{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Задание 4 - 10 баллов\n",
    "\n",
    "## Задание\n",
    "\n",
    "Исходный набор данных - [Fake and real news dataset](https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset)\n",
    "\n",
    "- Реализовать классификацию двумя моделями: CNN, LSTM - **6 баллов = 3 + 3**\n",
    "- Сравнить качество обученных моделей **1 балл**\n",
    "\n",
    "\n",
    "- Обеспечена воспроизводимость решения: зафиксированы random_state, ноутбук воспроизводится от начала до конца без ошибок - **2 балла**\n",
    "\n",
    "- Соблюден code style на уровне pep8 и [On writing clean Jupyter notebooks](https://ploomber.io/blog/clean-nbs/)  - **1 балл**\n",
    " \n",
    "Примеры: [Using Convolution Neural Networks to Classify Text in PyTorch](https://tzuruey.medium.com/using-convolution-neural-networks-to-classify-text-in-pytorch-3b626a42c3ca), [LSTM in Pytorch](https://wandb.ai/sauravmaheshkar/LSTM-PyTorch/reports/Using-LSTM-in-PyTorch-A-Tutorial-With-Examples--VmlldzoxMDA2NTA5)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5bacfe59f19b2e0"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "import spacy\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "SEED = 566\n",
    "# data dir\n",
    "DATA_DIR = \"../data\"\n",
    "\n",
    "DATA = \"../data/spam_or_not_spam.csv\"\n",
    "\n",
    "\n",
    "def classification_report_pd(y_test, y_pred):\n",
    "    report = pd.DataFrame(classification_report(y_true=y_test, y_pred=y_pred, output_dict=True)).transpose()\n",
    "    report.support = report.support.astype(int)\n",
    "    report.loc['accuracy', 'support'] = report.loc['macro avg', 'support']\n",
    "    report.loc['accuracy', 'precision'] = np.nan\n",
    "    report.loc['accuracy', 'recall'] = np.nan\n",
    "    return report"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T20:56:37.493978896Z",
     "start_time": "2023-11-01T20:56:34.019873129Z"
    }
   },
   "id": "7de067a035866bf9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Установка torch\n",
    "\n",
    "Попробую на своем компуктере запустить на CPU, если все будет плохо -- перейду в коллаб"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8263478de0dfbb27"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# ! pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T01:19:48.006180042Z",
     "start_time": "2023-10-31T01:19:47.925043879Z"
    }
   },
   "id": "fbce17e9592d6f47"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Подготовка данных\n",
    "\n",
    "Шаг 0:\n",
    "надо скачать и положить в директорию `../data/` эмбеддинги word2vec: [https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?resourcekey=0-wjGZdNAUop6WykTtMip30g](ссылка).\n",
    "\n",
    "И распаковать (чтобы был файл `.bin`).\n",
    "\n",
    "Шаг 1: качаю спам/нотспам датасет"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6dd392b6bd81c2c"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# !kaggle datasets download -d ozlerhakan/spam-or-not-spam-dataset\n",
    "# !mv ./spam-or-not-spam-dataset.zip ../data/\n",
    "# !unzip ../data/spam-or-not-spam-dataset.zip\n",
    "# !mv ./spam_or_not_spam.csv ../data/\n",
    "# !python -m spacy download en_core_web_sm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T20:56:37.897760328Z",
     "start_time": "2023-11-01T20:56:37.864459905Z"
    }
   },
   "id": "aafc5526d62d27a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  Чтение данных\n",
    "Сделаем все как в домашках ранее."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5682ff1861ea4f0f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "NLP = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def check_token(token):\n",
    "    return not (token.is_stop\n",
    "                or token.is_punct\n",
    "                or token.is_digit\n",
    "                or token.like_email\n",
    "                or token.like_num)  # like num в данном случае делать не обязательно (тут уже заменены все NUMBER), но сделал это для общности -- на будущее\n",
    "\n",
    "\n",
    "def tokenize_clean(text):\n",
    "    return [token.lemma_.lower() for token in NLP(text) if check_token(token)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T20:56:43.535624939Z",
     "start_time": "2023-11-01T20:56:42.984491173Z"
    }
   },
   "id": "ba0c1e9aa4c72a22"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2999, 2)\n",
      "Classes: label\n",
      "0    2500\n",
      "1     499\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                               email  label\n0   date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...      0\n1  martin a posted tassos papadopoulos the greek ...      0\n2  man threatens explosion in moscow thursday aug...      0\n3  klez the virus that won t die already the most...      0\n4   in adding cream to spaghetti carbonara which ...      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>email</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>martin a posted tassos papadopoulos the greek ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>man threatens explosion in moscow thursday aug...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>klez the virus that won t die already the most...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>in adding cream to spaghetti carbonara which ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(DATA)\n",
    "data = data[(~data['email'].isna()) & (data['label'].isin([0, 1]))]\n",
    "print('Shape:', data.shape)\n",
    "print('Classes:', data.label.value_counts())\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T20:56:44.984646705Z",
     "start_time": "2023-11-01T20:56:44.943087642Z"
    }
   },
   "id": "f163d6e9cfeb6861"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  email  label\n2919  register domains for just NUMBER NUMBER the ne...      1\n2920   generic v agra NUMBER per NUMBERmg generic v ...      1\n2921  hello you may have seen this business before a...      1\n2922  hello you may have seen this business before a...      1\n2923   the best mortage rates simple easy and free h...      1\n...                                                 ...    ...\n2995   abc s good morning america ranks it the NUMBE...      1\n2996   hyperlink hyperlink hyperlink let mortgage le...      1\n2997   thank you for shopping with us gifts for all ...      1\n2998   the famous ebay marketing e course learn to s...      1\n2999   hello this is chinese traditional 子 件 NUMBER世...      1\n\n[80 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>email</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2919</th>\n      <td>register domains for just NUMBER NUMBER the ne...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2920</th>\n      <td>generic v agra NUMBER per NUMBERmg generic v ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2921</th>\n      <td>hello you may have seen this business before a...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2922</th>\n      <td>hello you may have seen this business before a...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2923</th>\n      <td>the best mortage rates simple easy and free h...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2995</th>\n      <td>abc s good morning america ranks it the NUMBE...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2996</th>\n      <td>hyperlink hyperlink hyperlink let mortgage le...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2997</th>\n      <td>thank you for shopping with us gifts for all ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2998</th>\n      <td>the famous ebay marketing e course learn to s...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2999</th>\n      <td>hello this is chinese traditional 子 件 NUMBER世...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>80 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(80)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T20:58:42.538746980Z",
     "start_time": "2023-11-01T20:58:42.522232865Z"
    }
   },
   "id": "e0115c5e47add1a"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 469 ms, total: 1min 8s\n",
      "Wall time: 1min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                               email  label  \\\n0   date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...      0   \n1  martin a posted tassos papadopoulos the greek ...      0   \n2  man threatens explosion in moscow thursday aug...      0   \n3  klez the virus that won t die already the most...      0   \n4   in adding cream to spaghetti carbonara which ...      0   \n\n                                     email_tokenized  \n0  [ , date, d, number, aug, number, number, numb...  \n1  [martin, post, tassos, papadopoulo, greek, scu...  \n2  [man, threaten, explosion, moscow, thursday, a...  \n3  [klez, virus, win, t, die, prolific, virus, kl...  \n4  [ , add, cream, spaghetti, carbonara, effect, ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>email</th>\n      <th>label</th>\n      <th>email_tokenized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...</td>\n      <td>0</td>\n      <td>[ , date, d, number, aug, number, number, numb...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>martin a posted tassos papadopoulos the greek ...</td>\n      <td>0</td>\n      <td>[martin, post, tassos, papadopoulo, greek, scu...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>man threatens explosion in moscow thursday aug...</td>\n      <td>0</td>\n      <td>[man, threaten, explosion, moscow, thursday, a...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>klez the virus that won t die already the most...</td>\n      <td>0</td>\n      <td>[klez, virus, win, t, die, prolific, virus, kl...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>in adding cream to spaghetti carbonara which ...</td>\n      <td>0</td>\n      <td>[ , add, cream, spaghetti, carbonara, effect, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data['email_tokenized'] = data['email'].apply(tokenize_clean)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T01:20:56.754709964Z",
     "start_time": "2023-10-31T01:19:48.439278671Z"
    }
   },
   "id": "dea190b80c43197c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Подгрузим эмбеддинги"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a24143844e173c83"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0.10742188, -0.20117188,  0.12304688,  0.21191406, -0.09130859,\n        0.21679688, -0.13183594,  0.08300781,  0.20214844,  0.04785156],\n      dtype=float32)"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model = KeyedVectors.load_word2vec_format('../data/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "vector = w2v_model['computer']\n",
    "vector[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T01:42:08.277645008Z",
     "start_time": "2023-10-31T01:41:54.909811979Z"
    }
   },
   "id": "8db0d4524e0a7b8e"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def text_to_embedding(text):\n",
    "    vectors = []\n",
    "\n",
    "    for word in text:\n",
    "        if word in w2v_model:\n",
    "            vectors.append(w2v_model[word])\n",
    "\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(w2v_model.vector_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T01:21:13.016387999Z",
     "start_time": "2023-10-31T01:21:13.014595113Z"
    }
   },
   "id": "82454fa0535f7e12"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 464 ms, sys: 3.99 ms, total: 468 ms\n",
      "Wall time: 468 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                               email  label  \\\n0   date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...      0   \n1  martin a posted tassos papadopoulos the greek ...      0   \n2  man threatens explosion in moscow thursday aug...      0   \n3  klez the virus that won t die already the most...      0   \n4   in adding cream to spaghetti carbonara which ...      0   \n\n                                     email_tokenized  \\\n0  [ , date, d, number, aug, number, number, numb...   \n1  [martin, post, tassos, papadopoulo, greek, scu...   \n2  [man, threaten, explosion, moscow, thursday, a...   \n3  [klez, virus, win, t, die, prolific, virus, kl...   \n4  [ , add, cream, spaghetti, carbonara, effect, ...   \n\n                                      email_embedded  \n0  [0.033716675, 0.039779373, 0.018512992, 0.0509...  \n1  [-0.012349759, 0.035399687, -0.036836125, 0.12...  \n2  [0.018030634, 0.0055707716, 0.026558831, 0.046...  \n3  [0.051892176, 0.024502225, -0.029774984, 0.115...  \n4  [-0.07272888, 0.0076953126, 0.011092937, 0.189...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>email</th>\n      <th>label</th>\n      <th>email_tokenized</th>\n      <th>email_embedded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...</td>\n      <td>0</td>\n      <td>[ , date, d, number, aug, number, number, numb...</td>\n      <td>[0.033716675, 0.039779373, 0.018512992, 0.0509...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>martin a posted tassos papadopoulos the greek ...</td>\n      <td>0</td>\n      <td>[martin, post, tassos, papadopoulo, greek, scu...</td>\n      <td>[-0.012349759, 0.035399687, -0.036836125, 0.12...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>man threatens explosion in moscow thursday aug...</td>\n      <td>0</td>\n      <td>[man, threaten, explosion, moscow, thursday, a...</td>\n      <td>[0.018030634, 0.0055707716, 0.026558831, 0.046...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>klez the virus that won t die already the most...</td>\n      <td>0</td>\n      <td>[klez, virus, win, t, die, prolific, virus, kl...</td>\n      <td>[0.051892176, 0.024502225, -0.029774984, 0.115...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>in adding cream to spaghetti carbonara which ...</td>\n      <td>0</td>\n      <td>[ , add, cream, spaghetti, carbonara, effect, ...</td>\n      <td>[-0.07272888, 0.0076953126, 0.011092937, 0.189...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data['email_embedded'] = data['email_tokenized'].apply(text_to_embedding)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T01:21:13.502093917Z",
     "start_time": "2023-10-31T01:21:13.014875966Z"
    }
   },
   "id": "bba25b4b047e61e2"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "label\n0    1750\n1     349\nName: count, dtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "label\n0    375\n1     75\nName: count, dtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "label\n0    375\n1     75\nName: count, dtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = data[['email_tokenized', 'email_embedded']], data.label\n",
    "\n",
    "X_train, X_tv, y_train, y_tv = train_test_split(X,\n",
    "                                                y,\n",
    "                                                test_size=0.3,\n",
    "                                                random_state=SEED,\n",
    "                                                stratify=y)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_tv,\n",
    "                                                y_tv,\n",
    "                                                test_size=0.5,\n",
    "                                                random_state=SEED,\n",
    "                                                stratify=y_tv)\n",
    "\n",
    "display(y_train.value_counts())\n",
    "display(y_val.value_counts())\n",
    "display(y_test.value_counts())\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "y_val = y_val.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T01:21:13.502741428Z",
     "start_time": "2023-10-31T01:21:13.471255178Z"
    }
   },
   "id": "195691e753e04a65"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Text 2 sequence\n",
    "\n",
    "Кроме эмбеддингов превратим еще тексты в последовательности с помощью словаря токенов (1 слово -- 1 токен). Именно этот метод будет использоваться для обучения нейронок в этом дз, но эмбеддинги выше решил оставить -- чтобы не потерялось, когда буду делать дальнейшие ДЗ."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b21a0634ee7d6e8"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "13"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    for word in text:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "    padding = [0] * (maxlen - len(result))\n",
    "    return padding + result[-maxlen:]\n",
    "\n",
    "\n",
    "tokens = []\n",
    "for text in X_train:\n",
    "    tokens.extend(text)\n",
    "\n",
    "max_words = 2000\n",
    "dist = FreqDist(tokens)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words - 1)]\n",
    "tokens_filtered_top[:10]\n",
    "\n",
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}\n",
    "len(vocabulary)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T01:21:13.550631107Z",
     "start_time": "2023-10-31T01:21:13.485120896Z"
    }
   },
   "id": "d3bd6cfb59263f7"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальная длина предложения: 184 \n"
     ]
    }
   ],
   "source": [
    "max_len = int(np.quantile(data.email_tokenized.apply(lambda x: len(x)), 0.85))\n",
    "print(f\"Максимальная длина предложения: {max_len} \")\n",
    "Xp_train = np.array([text_to_sequence(text, max_len) for text in X_train['email_tokenized']], dtype=np.int32)\n",
    "Xp_test = np.array([text_to_sequence(text, max_len) for text in X_test['email_tokenized']], dtype=np.int32)\n",
    "Xp_val = np.array([text_to_sequence(text, max_len) for text in X_val['email_tokenized']], dtype=np.int32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T01:21:13.655383355Z",
     "start_time": "2023-10-31T01:21:13.490550824Z"
    }
   },
   "id": "32f21872b18ba8fe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Torch\n",
    "\n",
    "Способ выше -- превратили в числа, и приделали паддинги -- как на уроке, \n",
    "\n",
    "Еще научимся эмбеденные слова превращать в тензоры (это при построении нейронок не использовалось, но чтобы не потерять, оставлю это тут на будущее -- надеюсь не критично). "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4dc54b5d07ee8b84"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1, 0, ..., 0, 0, 0])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T01:21:50.152455004Z",
     "start_time": "2023-10-31T01:21:50.127637226Z"
    }
   },
   "id": "af81947ad6defe5e"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "Xt_train, yt_train = torch.tensor([x for x in X_train['email_embedded']]), torch.tensor(y_train)\n",
    "Xt_val, yt_val = torch.tensor([x for x in X_val['email_embedded']]), torch.tensor(y_val)\n",
    "Xt_test, yt_test = torch.tensor([x for x in X_test['email_embedded']]), torch.tensor(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T01:22:04.348010806Z",
     "start_time": "2023-10-31T01:22:04.314235406Z"
    }
   },
   "id": "615a01dcecdde72a"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class TextDataWrapper(Dataset):\n",
    "    def __init__(self, data, target=None, transform=None):\n",
    "        self.data = torch.from_numpy(data).long()\n",
    "        if target is not None:\n",
    "            self.target = torch.from_numpy(target).long()\n",
    "        else:\n",
    "            self.target = None\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index] if self.target is not None else -1\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T01:22:07.285262863Z",
     "start_time": "2023-10-31T01:22:07.255180589Z"
    }
   },
   "id": "e7b1485415eb1c6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0183fa1430e5f96"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size=2000, embedding_dim=128, out_channel=128, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.conv = nn.Conv1d(embedding_dim, out_channel, kernel_size=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(out_channel, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.embedding(x)\n",
    "        output = output.permute(0, 2, 1)  # bs, emb_dim, len\n",
    "        output = self.conv(output)\n",
    "        output = self.relu(output)\n",
    "        output = torch.max(output, axis=2).values\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size=2000, embedding_dim=128, hidden_dim=64, num_layers=1, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=False)\n",
    "        self.linear = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(output)\n",
    "        final_hidden_state = lstm_out[:, -1, :]\n",
    "        output = self.linear(final_hidden_state)\n",
    "        return output\n",
    "\n",
    "\n",
    "model_cnn = CNNClassifier()\n",
    "model_lstm = LSTMClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T01:22:08.975004886Z",
     "start_time": "2023-10-31T01:22:08.931813791Z"
    }
   },
   "id": "8e869403b70caa33"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare and train CNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e0f672258b1e5f8"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNClassifier(\n",
      "  (embedding): Embedding(2000, 128)\n",
      "  (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  (relu): ReLU()\n",
      "  (linear): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "Parameters: 305538\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "num_epochs = 100\n",
    "print(model_cnn)\n",
    "print(\"Parameters:\", sum([param.nelement() for param in model_cnn.parameters()]))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = model_cnn.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_dataset = TextDataWrapper(Xp_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = TextDataWrapper(Xp_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T01:22:10.999413410Z",
     "start_time": "2023-10-31T01:22:10.739736913Z"
    }
   },
   "id": "c812156190eb0a6e"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.3727441496319241, Train Accuracy: 86.15%, Val Accuracy: 84.85%\n",
      "Epoch 20/100, Loss: 0.35570215847757125, Train Accuracy: 87.02%, Val Accuracy: 85.11%\n",
      "Epoch 30/100, Loss: 0.3505771789285872, Train Accuracy: 87.10%, Val Accuracy: 85.49%\n",
      "Epoch 40/100, Loss: 0.32878520091374713, Train Accuracy: 87.41%, Val Accuracy: 85.17%\n",
      "Epoch 50/100, Loss: 0.33881500032212997, Train Accuracy: 87.54%, Val Accuracy: 84.92%\n",
      "Epoch 60/100, Loss: 0.34424579805798, Train Accuracy: 87.19%, Val Accuracy: 85.24%\n",
      "Epoch 70/100, Loss: 0.3126346833176083, Train Accuracy: 86.97%, Val Accuracy: 84.53%\n",
      "Epoch 80/100, Loss: 0.33494001626968384, Train Accuracy: 87.02%, Val Accuracy: 85.48%\n",
      "Epoch 90/100, Loss: 0.3336748215887282, Train Accuracy: 86.93%, Val Accuracy: 85.05%\n",
      "Epoch 100/100, Loss: 0.3204502794477675, Train Accuracy: 87.71%, Val Accuracy: 85.42%\n",
      "CPU times: user 7min 12s, sys: 34.3 s, total: 7min 46s\n",
      "Wall time: 60 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    temp_train_losses = []\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        temp_train_losses.append(loss.float().item())\n",
    "    train_losses.append(np.mean(temp_train_losses))\n",
    "\n",
    "    if epoch % 10 == 9:\n",
    "        # Validation accuracy\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            temp_train_acc = []\n",
    "            temp_val_acc = []\n",
    "            for i, (data, target) in enumerate(train_loader):\n",
    "                train_outputs = model(data).squeeze()\n",
    "                temp_train_acc.append(np.array((model(data).argmax(1) == target).int()).mean())\n",
    "            for i, (data, target) in enumerate(val_loader):\n",
    "                val_outputs = model(data).squeeze()\n",
    "                temp_val_acc.append(np.array((model(data).argmax(1) == target).int()).mean())\n",
    "            val_accuracies.append(np.mean(temp_val_acc))\n",
    "            train_accuracies.append(np.mean(temp_train_acc))\n",
    "\n",
    "        print(\n",
    "            f'Epoch {epoch + 1}/{num_epochs}, Loss: {train_losses[-1]}, Train Accuracy: {train_accuracies[-1] * 100:.2f}%, Val Accuracy: {val_accuracies[-1] * 100:.2f}%')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T01:23:12.549060241Z",
     "start_time": "2023-10-31T01:22:12.569639452Z"
    }
   },
   "id": "67fe7b67c53d439a"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "CNN_MODEL_TRAINED = deepcopy(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T01:23:12.549264529Z",
     "start_time": "2023-10-31T01:23:12.546237351Z"
    }
   },
   "id": "988a9772685316e1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare and train LSTM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4f61baca0c98ff5"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMClassifier(\n",
      "  (embedding): Embedding(2000, 128)\n",
      "  (lstm): LSTM(128, 64, batch_first=True)\n",
      "  (linear): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "Parameters: 305538\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "num_epochs = 100\n",
    "print(model_lstm)\n",
    "print(\"Parameters:\", sum([param.nelement() for param in model_cnn.parameters()]))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = model_lstm.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_dataset = TextDataWrapper(Xp_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = TextDataWrapper(Xp_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T01:23:12.549441906Z",
     "start_time": "2023-10-31T01:23:12.546395141Z"
    }
   },
   "id": "ecf4805f80e32333"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.4076301058133443, Train Accuracy: 83.97%, Val Accuracy: 85.56%\n",
      "Epoch 20/100, Loss: 0.37447400556670296, Train Accuracy: 85.76%, Val Accuracy: 86.51%\n",
      "Epoch 30/100, Loss: 0.35908017887009513, Train Accuracy: 86.54%, Val Accuracy: 86.19%\n",
      "Epoch 40/100, Loss: 0.35851213998264736, Train Accuracy: 86.54%, Val Accuracy: 85.55%\n",
      "Epoch 50/100, Loss: 0.3640291723940108, Train Accuracy: 87.10%, Val Accuracy: 86.21%\n",
      "Epoch 60/100, Loss: 0.3537207245826721, Train Accuracy: 87.32%, Val Accuracy: 86.14%\n",
      "Epoch 70/100, Loss: 0.33135310146543717, Train Accuracy: 87.37%, Val Accuracy: 85.57%\n",
      "Epoch 80/100, Loss: 0.3299876418378618, Train Accuracy: 87.58%, Val Accuracy: 85.57%\n",
      "Epoch 90/100, Loss: 0.3293519483672248, Train Accuracy: 88.11%, Val Accuracy: 85.17%\n",
      "Epoch 100/100, Loss: 0.3050866706503762, Train Accuracy: 86.54%, Val Accuracy: 85.25%\n",
      "CPU times: user 8min 29s, sys: 1min 48s, total: 10min 17s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    temp_train_losses = []\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        temp_train_losses.append(loss.float().item())\n",
    "    train_losses.append(np.mean(temp_train_losses))\n",
    "\n",
    "    if epoch % 10 == 9:\n",
    "        # Validation accuracy\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            temp_train_acc = []\n",
    "            temp_val_acc = []\n",
    "            for i, (data, target) in enumerate(train_loader):\n",
    "                train_outputs = model(data).squeeze()\n",
    "                temp_train_acc.append(np.array((model(data).argmax(1) == target).int()).mean())\n",
    "            for i, (data, target) in enumerate(val_loader):\n",
    "                val_outputs = model(data).squeeze()\n",
    "                temp_val_acc.append(np.array((model(data).argmax(1) == target).int()).mean())\n",
    "            val_accuracies.append(np.mean(temp_val_acc))\n",
    "            train_accuracies.append(np.mean(temp_train_acc))\n",
    "\n",
    "        print(\n",
    "            f'Epoch {epoch + 1}/{num_epochs}, Loss: {train_losses[-1]}, Train Accuracy: {train_accuracies[-1] * 100:.2f}%, Val Accuracy: {val_accuracies[-1] * 100:.2f}%')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T01:24:35.141470657Z",
     "start_time": "2023-10-31T01:23:12.546476255Z"
    }
   },
   "id": "9b9395360d9565bd"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "LSTM_MODEL_TRAINED = deepcopy(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T01:27:11.390398656Z",
     "start_time": "2023-10-31T01:27:11.335926194Z"
    }
   },
   "id": "21f3bb7417b310b7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Сравним две модели"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85dd8c9b930d373d"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM\n"
     ]
    },
    {
     "data": {
      "text/plain": "              precision    recall  f1-score  support\n0              0.860577  0.954667  0.905183      375\n1              0.500000  0.226667  0.311927       75\naccuracy            NaN       NaN  0.833333      450\nmacro avg      0.680288  0.590667  0.608555      450\nweighted avg   0.800481  0.833333  0.806307      450",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n      <th>support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.860577</td>\n      <td>0.954667</td>\n      <td>0.905183</td>\n      <td>375</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.500000</td>\n      <td>0.226667</td>\n      <td>0.311927</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>accuracy</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.833333</td>\n      <td>450</td>\n    </tr>\n    <tr>\n      <th>macro avg</th>\n      <td>0.680288</td>\n      <td>0.590667</td>\n      <td>0.608555</td>\n      <td>450</td>\n    </tr>\n    <tr>\n      <th>weighted avg</th>\n      <td>0.800481</td>\n      <td>0.833333</td>\n      <td>0.806307</td>\n      <td>450</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "array([[358,  17],\n       [ 58,  17]])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN\n"
     ]
    },
    {
     "data": {
      "text/plain": "              precision    recall  f1-score  support\n0              0.856459  0.954667  0.902900      375\n1              0.468750  0.200000  0.280374       75\naccuracy            NaN       NaN  0.828889      450\nmacro avg      0.662605  0.577333  0.591637      450\nweighted avg   0.791841  0.828889  0.799146      450",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n      <th>support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.856459</td>\n      <td>0.954667</td>\n      <td>0.902900</td>\n      <td>375</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.468750</td>\n      <td>0.200000</td>\n      <td>0.280374</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>accuracy</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.828889</td>\n      <td>450</td>\n    </tr>\n    <tr>\n      <th>macro avg</th>\n      <td>0.662605</td>\n      <td>0.577333</td>\n      <td>0.591637</td>\n      <td>450</td>\n    </tr>\n    <tr>\n      <th>weighted avg</th>\n      <td>0.791841</td>\n      <td>0.828889</td>\n      <td>0.799146</td>\n      <td>450</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "array([[358,  17],\n       [ 60,  15]])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, model in zip(['LSTM', 'CNN'], [LSTM_MODEL_TRAINED, CNN_MODEL_TRAINED]):\n",
    "    print(name)    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(data).squeeze().argmax(1).int().numpy()\n",
    "        display(classification_report_pd(y_test, y_pred))\n",
    "        display(confusion_matrix(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T01:34:05.609084786Z",
     "start_time": "2023-10-31T01:34:05.416168367Z"
    }
   },
   "id": "f86634aa18ae1ff4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Из выведенных метрик видно, что LST лучше справилась с задачей, чем CNN. Возможно, если начать подбор гиперпараметров (количество слоев, нейронов в каждом слое), то модели выучатся лучше, и метрики будут поближе к единице. \n",
    "\n",
    "Кроме того, данных определенно не хватает. Если взять другой (побольше) датасет -- определенно получилось бы лучше. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97efea172830c2c1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
