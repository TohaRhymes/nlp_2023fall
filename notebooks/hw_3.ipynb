{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Задание 3 - 10 баллов\n",
    "\n",
    "- Загрузить набор данных [Spam Or Not Spam](https://www.kaggle.com/datasets/ozlerhakan/spam-or-not-spam-dataset) (или любой другой, какой вам нравится)\n",
    "- Обучить модели и сравнить различные способы векторизации с помощью внутренней оценки (intrinsic):\n",
    "  - Word2Vec SkipGram / CBOW (параметр sg в `gensim.models.word2vec.Word2Vec`) - **3 балла**\n",
    "  - fastText (можно взять в gensim, или в fasttext как на семинаре) - **2 балла**\n",
    "- Обучить на полученных векторах модели LogisticRegression и сравнить качество на отложенной выборке - **2 балла**\n",
    "\n",
    "- Обеспечена воспроизводимость решения: зафиксированы random_state, ноутбук воспроизводится от начала до конца без ошибок - **2 балла**\n",
    "\n",
    "- Соблюден code style на уровне pep8 и [On writing clean Jupyter notebooks](https://ploomber.io/blog/clean-nbs/)  - **1 балл**\n",
    " \n",
    "Примечания:\n",
    "\n",
    "- Для получения более качественных эмбеддингов стоит предварительно сделать предобработку корпуса - отсеять стоп-слова, провести нормализацию и тп. Предобработка рассматривалась в первой лекции/семинаре\n",
    "- В данном случае под intrinsic оценкой подразумевается просто использование методов `most_similar`, `doesnt_match`. Однако, если есть желание, можно измерить косинусное расстояние между отдельными парами слов и проверить, есть ли корреляция с корпусами для intrinsic-оценки, которые обсуждались на семинаре\n",
    "\n",
    "\n",
    "## Все библиотеки и константы\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ced8f2857d4b54ce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Импортируем, добавляем константы, функции"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be8710912b1cf917"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import FastText\n",
    "import warnings\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import spacy\n",
    "\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "SEED = 566\n",
    "# data dir\n",
    "DATA_DIR = \"../data\"\n",
    "\n",
    "DATA = \"../data/spam_or_not_spam.csv\"\n",
    "\n",
    "\n",
    "def classification_report_pd(y_test, y_pred):\n",
    "    report = pd.DataFrame(classification_report(y_true=y_test, y_pred=y_pred, output_dict=True)).transpose()\n",
    "    report.support = report.support.astype(int)\n",
    "    report.loc['accuracy', 'support'] = report.loc['macro avg', 'support']\n",
    "    report.loc['accuracy', 'precision'] = np.nan\n",
    "    report.loc['accuracy', 'recall'] = np.nan\n",
    "    return report\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:00:58.339469128Z",
     "start_time": "2023-10-14T15:00:57.197795808Z"
    }
   },
   "id": "f3b1fd6957cc3832"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:00:58.383105039Z",
     "start_time": "2023-10-14T15:00:58.382802176Z"
    }
   },
   "id": "8e23fa52223df1e8"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/toharhymes/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/toharhymes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:00:58.433569096Z",
     "start_time": "2023-10-14T15:00:58.383008410Z"
    }
   },
   "id": "f1e186d1e04028b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Загрузка данных\n",
    "\n",
    "Disclaimer: Я сначала попробовал поработать с данными из первого ДЗ -- предсказывать топики, но так как там классов (топиков) много, то все очень плохо обучалось, решил взять из второго ДЗ на англоязычных текстах spam-not spam.\n",
    "\n",
    "(не забудьте раскоментить):"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0878da9f69cd69f"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# !kaggle datasets download -d ozlerhakan/spam-or-not-spam-dataset\n",
    "# !mv ./spam-or-not-spam-dataset.zip ../data/\n",
    "# !unzip ../data/spam-or-not-spam-dataset.zip\n",
    "# !mv ./spam_or_not_spam.csv ../data/\n",
    "# !python -m spacy download en_core_web_sm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:00:58.434957418Z",
     "start_time": "2023-10-14T15:00:58.429772967Z"
    }
   },
   "id": "9f4c07f8750fd345"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Читаем датасет"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4548e3ba14a4e1d9"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2999, 2)\n",
      "Classes: label\n",
      "0    2500\n",
      "1     499\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                               email  label\n0   date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...      0\n1  martin a posted tassos papadopoulos the greek ...      0\n2  man threatens explosion in moscow thursday aug...      0\n3  klez the virus that won t die already the most...      0\n4   in adding cream to spaghetti carbonara which ...      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>email</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>martin a posted tassos papadopoulos the greek ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>man threatens explosion in moscow thursday aug...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>klez the virus that won t die already the most...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>in adding cream to spaghetti carbonara which ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(DATA)\n",
    "data = data[(~data['email'].isna()) & (data['label'].isin([0, 1]))]\n",
    "print('Shape:', data.shape)\n",
    "print('Classes:', data.label.value_counts())\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:00:58.514312588Z",
     "start_time": "2023-10-14T15:00:58.431961577Z"
    }
   },
   "id": "cf593ae834ba8f35"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Предобработка\n",
    "\n",
    "Проведем предобработку данных, используя методы, похожие первой лабораторной:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "355f62543aa63bb7"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "NLP = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def check_token(token):\n",
    "    return not (token.is_stop\n",
    "                or token.is_punct\n",
    "                or token.is_digit\n",
    "                or token.like_email\n",
    "                or token.like_num)  # like num в данном случае делать не обязательно (тут уже заменены все NUMBER), но сделал это для общности -- на будущее\n",
    "\n",
    "\n",
    "def tokenize_clean(text):\n",
    "    return [token.lemma_.lower() for token in NLP(text) if check_token(token)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:00:58.783667730Z",
     "start_time": "2023-10-14T15:00:58.470230528Z"
    }
   },
   "id": "8829678cbcc2edd2"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min, sys: 467 ms, total: 1min\n",
      "Wall time: 1min\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                               email  label  \\\n0   date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...      0   \n1  martin a posted tassos papadopoulos the greek ...      0   \n2  man threatens explosion in moscow thursday aug...      0   \n3  klez the virus that won t die already the most...      0   \n4   in adding cream to spaghetti carbonara which ...      0   \n\n                                     email_tokenized  \n0  [ , date, d, number, aug, number, number, numb...  \n1  [martin, post, tassos, papadopoulo, greek, scu...  \n2  [man, threaten, explosion, moscow, thursday, a...  \n3  [klez, virus, win, t, die, prolific, virus, kl...  \n4  [ , add, cream, spaghetti, carbonara, effect, ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>email</th>\n      <th>label</th>\n      <th>email_tokenized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...</td>\n      <td>0</td>\n      <td>[ , date, d, number, aug, number, number, numb...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>martin a posted tassos papadopoulos the greek ...</td>\n      <td>0</td>\n      <td>[martin, post, tassos, papadopoulo, greek, scu...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>man threatens explosion in moscow thursday aug...</td>\n      <td>0</td>\n      <td>[man, threaten, explosion, moscow, thursday, a...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>klez the virus that won t die already the most...</td>\n      <td>0</td>\n      <td>[klez, virus, win, t, die, prolific, virus, kl...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>in adding cream to spaghetti carbonara which ...</td>\n      <td>0</td>\n      <td>[ , add, cream, spaghetti, carbonara, effect, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data['email_tokenized'] = data['email'].apply(tokenize_clean)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:01:59.376378672Z",
     "start_time": "2023-10-14T15:00:58.785368963Z"
    }
   },
   "id": "1d8a887943f32564"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1abdf7e2fb400bb"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "label\n0    2000\n1     399\nName: count, dtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "label\n0    500\n1    100\nName: count, dtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = data.email_tokenized, data.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=SEED,\n",
    "                                                    stratify=y)\n",
    "\n",
    "display(y_train.value_counts())\n",
    "display(y_test.value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:01:59.377009627Z",
     "start_time": "2023-10-14T15:01:59.354999963Z"
    }
   },
   "id": "4aedcdb36daaf35"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Учим Эмбеддинги\n",
    "\n",
    "### Word2Vec SkipGram / CBOW\n",
    "\n",
    "Попробую и skip=gram и CBOW, и погляжу, что лучше обучилось (все остальные параметры оставлю одинаковыми)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a4e54c9eba90702"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 30s, sys: 374 ms, total: 2min 30s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_skipgram = Word2Vec(\n",
    "    sentences=X_train,\n",
    "    vector_size=300,  # default = 100\n",
    "    window=5,  # default = 5\n",
    "    min_count=10,\n",
    "    sg=1,  # Training algorithm: 1 for skip-gram; otherwise CBOW\n",
    "    hs=0,  #  1 - hierarchical softmax. 0, and negative>0 - negative sampling.\n",
    "    negative=5,  # If > 0 -- negative sampling will be used\n",
    "    epochs=40,  # epochs over the corpus\n",
    "    seed=SEED,\n",
    "    workers=16\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:02:12.533332718Z",
     "start_time": "2023-10-14T15:01:59.355250260Z"
    }
   },
   "id": "5919b0ee5d438fa1"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.4 s, sys: 184 ms, total: 27.6 s\n",
      "Wall time: 4.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_cbow = Word2Vec(\n",
    "    sentences=X_train,\n",
    "    vector_size=300,  # default = 100\n",
    "    window=5,  # default = 5\n",
    "    min_count=10,\n",
    "    sg=0,  # Training algorithm: 1 for skip-gram; otherwise CBOW\n",
    "    hs=0,  #  1 - hierarchical softmax. 0, and negative>0 - negative sampling.\n",
    "    negative=5,  # If > 0 -- negative sampling will be used\n",
    "    epochs=40,  # epochs over the corpus\n",
    "    seed=SEED,\n",
    "    workers=16\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:02:17.529078086Z",
     "start_time": "2023-10-14T15:02:12.562227484Z"
    }
   },
   "id": "e47f088be6aedc73"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "([('gnat', 0.46857908368110657),\n  ('tuesday', 0.4551939368247986),\n  ('rafael', 0.44891849160194397),\n  ('ziggy', 0.3902868926525116),\n  ('porter', 0.3701557517051697)],\n [('august', 0.7366386651992798),\n  ('tuesday', 0.7045066952705383),\n  ('december', 0.690962016582489),\n  ('september', 0.649682343006134),\n  ('february', 0.6377255916595459)])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_skipgram.wv.most_similar(positive=['october'], topn=5), model_cbow.wv.most_similar(positive=['october'], topn=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:02:17.552964293Z",
     "start_time": "2023-10-14T15:02:17.520114233Z"
    }
   },
   "id": "f6cd3b4e587468d1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cbow выглядит получше -- просто  месяцы выдает, а не что-то непонятное."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0d9089431024f62"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "([('teen', 0.43621835112571716),\n  ('sexy', 0.43331652879714966),\n  ('xxx', 0.4104221761226654),\n  ('orlando', 0.39990732073783875),\n  ('servant', 0.38169562816619873)],\n [('teen', 0.6404370665550232),\n  ('xxx', 0.5881308317184448),\n  ('cum', 0.5460056066513062),\n  ('sexy', 0.5423579216003418),\n  ('fucking', 0.5155233144760132)])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_skipgram.wv.most_similar(positive=['girl'], topn=5), model_cbow.wv.most_similar(positive=['girl'], topn=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:02:17.635363198Z",
     "start_time": "2023-10-14T15:02:17.530145186Z"
    }
   },
   "id": "dd0be6275447ffcc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Из-за специфики текстов, немного специфичное окружение слова \"girl\", ну а что поделать."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd6623ade8608b2e"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "([('upfront', 0.4077613651752472),\n  ('consignment', 0.3211933672428131),\n  ('mega', 0.3172152638435364),\n  ('investment', 0.3057568371295929),\n  ('agm', 0.3055465817451477)],\n [('investment', 0.4264647364616394),\n  ('incredibly', 0.37271201610565186),\n  ('cash', 0.3530132472515106),\n  ('pocket', 0.3332630395889282),\n  ('estate', 0.3321537971496582)])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_skipgram.wv.most_similar(positive=['money'], topn=5), model_cbow.wv.most_similar(positive=['money'], topn=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:02:17.636068062Z",
     "start_time": "2023-10-14T15:02:17.538252563Z"
    }
   },
   "id": "8fa98cc1a243ad8b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Кажется, что тоже cbow получше."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f7ff792ea0703b6"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c3dd6a52c5f3b082"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "([('upfront', 0.23783999681472778),\n  ('acquisition', 0.19944292306900024),\n  ('payment', 0.17025168240070343),\n  ('la', 0.16988345980644226),\n  ('government', 0.16855306923389435),\n  ('devote', 0.16733218729496002)],\n [('plus', 0.3156777620315552),\n  ('pocket', 0.2928771674633026),\n  ('payment', 0.2808143198490143),\n  ('p', 0.27176758646965027),\n  ('thailand', 0.2545802593231201),\n  ('assist', 0.24979622662067413)])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_skipgram.wv.most_similar(positive=['money'], negative=[\"win\"])[:6], model_cbow.wv.most_similar(\n",
    "    positive=['money'], negative=[\"win\"])[:6]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:02:17.691290145Z",
     "start_time": "2023-10-14T15:02:17.548747430Z"
    }
   },
   "id": "de4665aee408e0b8"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "([('february', 0.19939151406288147),\n  ('template', 0.17645825445652008),\n  ('inter', 0.17278490960597992),\n  ('paragraph', 0.16987238824367523),\n  ('assertion', 0.1673910915851593),\n  ('namespace', 0.16625744104385376)],\n [('cite', 0.4572882056236267),\n  ('relevant', 0.4489752948284149),\n  ('hebrew', 0.4096534252166748),\n  ('transmit', 0.40616336464881897),\n  ('assessment', 0.3861862123012543),\n  ('inter', 0.38413017988204956)])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_skipgram.wv.most_similar(positive=['document'], negative=[\"money\"])[:6], model_cbow.wv.most_similar(\n",
    "    positive=['document'],\n",
    "    negative=[\"money\"])[\n",
    "                                                                               :6]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:02:17.691626892Z",
     "start_time": "2023-10-14T15:02:17.595065572Z"
    }
   },
   "id": "dc5d2307754099a8"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "([('undergraduate', 0.46846500039100647),\n  ('graduate', 0.4104095995426178),\n  ('appoint', 0.3900448977947235),\n  ('college', 0.35854992270469666),\n  ('phd', 0.3525552451610565),\n  ('forbe', 0.349665105342865)],\n [('undergraduate', 0.5715292096138),\n  ('graduate', 0.5712165832519531),\n  ('education', 0.5570700168609619),\n  ('degree', 0.5340072512626648),\n  ('science', 0.533780574798584),\n  ('academic', 0.48827579617500305)])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_skipgram.wv.most_similar(positive=['study', \"school\"])[:6], model_cbow.wv.most_similar(\n",
    "    positive=['study', \"school\"])[:6]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:02:17.691754741Z",
     "start_time": "2023-10-14T15:02:17.595295090Z"
    }
   },
   "id": "3c1d44affd64f11a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "В последнем случае очень похоже, классно. В целом хороши оба, но на глазок, cbow в чем-то лучше."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bddd8e7d18c38b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fasttext\n",
    "\n",
    "Сама библиотека fasttext отказывается вставать, поэтому воспользуемся fasttext'ом из gensim'a"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12f040c1a93c0814"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 34s, sys: 2.06 s, total: 6min 36s\n",
      "Wall time: 44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_fasttext = FastText(vector_size=300,\n",
    "                          window=5,\n",
    "                          min_count=1,\n",
    "                          sentences=X_train,\n",
    "                          epochs=40,\n",
    "                          seed=SEED,\n",
    "                          workers=16)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:03:01.712790817Z",
     "start_time": "2023-10-14T15:02:17.595404023Z"
    }
   },
   "id": "e90b85f5f4ed737e"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "[('november', 0.8149967789649963),\n ('octobre', 0.7829334139823914),\n ('sober', 0.7816057205200195),\n ('december', 0.7784882187843323),\n ('bomber', 0.7690507173538208)]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fasttext.wv.most_similar(positive=['october'], topn=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:03:01.713387711Z",
     "start_time": "2023-10-14T15:03:01.670955120Z"
    }
   },
   "id": "3135b94fae9ea727"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "[('peegirl', 0.8596227169036865),\n ('giro', 0.8107101321220398),\n ('peegirls', 0.7703859210014343),\n ('gimmicky', 0.6342937350273132),\n ('schoolgirl', 0.6258540749549866)]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fasttext.wv.most_similar(positive=['girl'], topn=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:03:01.713653918Z",
     "start_time": "2023-10-14T15:03:01.671168949Z"
    }
   },
   "id": "8438b183ca313d03"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "[('easymoney', 0.9122400879859924),\n ('foundmoney', 0.9036589860916138),\n ('mooney', 0.9009780883789062),\n ('honey', 0.8917720913887024),\n ('moneystarte', 0.8832082748413086)]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fasttext.wv.most_similar(positive=['money'], topn=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:03:01.713902182Z",
     "start_time": "2023-10-14T15:03:01.671273163Z"
    }
   },
   "id": "206e2e78a5dff039"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "[('foundmoney', 0.6533924341201782),\n ('honey', 0.6199032068252563),\n ('easymoney', 0.6172727346420288),\n ('mooney', 0.6161479353904724),\n ('moneystarte', 0.6013731956481934),\n ('clooney', 0.5991310477256775)]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fasttext.wv.most_similar(positive=['money'], negative=[\"win\"])[:6]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:03:01.714145496Z",
     "start_time": "2023-10-14T15:03:01.671372038Z"
    }
   },
   "id": "98593cfb3b09600f"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "[('documentary', 0.6510372757911682),\n ('documentum', 0.6248524188995361),\n ('entanglement', 0.5791913866996765),\n ('notamment', 0.5538952946662903),\n ('environnementaux', 0.5495142340660095),\n ('clements', 0.54843670129776)]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fasttext.wv.most_similar(positive=['document'], negative=[\"money\"])[:6]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:03:01.715957770Z",
     "start_time": "2023-10-14T15:03:01.671454823Z"
    }
   },
   "id": "a4f1b56f8376c6c5"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "([('schoolgirls', 0.7406686544418335),\n  ('schoolchildren', 0.7239114046096802),\n  ('schoolmate', 0.7111110091209412),\n  ('scholar', 0.6989538073539734),\n  ('preschool', 0.6978604197502136),\n  ('schoolgirl', 0.6958659291267395)],)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fasttext.wv.most_similar(positive=['study', \"school\"])[:6],"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:03:01.716340384Z",
     "start_time": "2023-10-14T15:03:01.680716524Z"
    }
   },
   "id": "d162b14483a45956"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Тут в основном производятся разные формы слова, а не синонимы ну -- тоже интересно. Посмотрим, что будет лучше.\n",
    "Для начала получим векторы этих текстов:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6dc16f3118f4028"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def text_embedding(text, model):\n",
    "    vectors = [model.wv[word] if word in model.wv else np.empty(300) for word in text]\n",
    "    embedding = np.nanmean(vectors, axis=0)\n",
    "    return embedding\n",
    "\n",
    "\n",
    "def corpus_embedding(corpus, model):\n",
    "    # Get the vector for each word and average them\n",
    "    embeddings = [text_embedding(text, model) for text in corpus]\n",
    "    return embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:03:01.716471308Z",
     "start_time": "2023-10-14T15:03:01.691251633Z"
    }
   },
   "id": "9fc915ead755ac1c"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbow\n",
      "(2399, 300) (600, 300)\n",
      "skipgram\n",
      "(2399, 300) (600, 300)\n",
      "fasttext\n",
      "(2399, 300) (600, 300)\n",
      "CPU times: user 2.43 s, sys: 683 ms, total: 3.11 s\n",
      "Wall time: 2.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embedding_models = {'cbow': model_cbow,\n",
    "                    'skipgram': model_skipgram,\n",
    "                    'fasttext': model_fasttext}\n",
    "X_trains = dict()\n",
    "X_tests = dict()\n",
    "for model_name in embedding_models:\n",
    "    print(model_name)\n",
    "    X_trains[model_name] = np.array(corpus_embedding(X_train, embedding_models[model_name]))\n",
    "    X_tests[model_name] = np.array(corpus_embedding(X_test, embedding_models[model_name]))\n",
    "    print(X_trains[model_name].shape, X_tests[model_name].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:03:03.996742244Z",
     "start_time": "2023-10-14T15:03:01.701619179Z"
    }
   },
   "id": "3d302d7241aa8d6a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Предсказание"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f42322e8fd67579"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:03:03.997826258Z",
     "start_time": "2023-10-14T15:03:03.978874774Z"
    }
   },
   "id": "4da9111045831fe0"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "grid = {\"lr__C\": np.linspace(0.1, 1, 10),\n",
    "        \"lr__penalty\": (\"l1\", \"l2\"),\n",
    "        \"lr__random_state\": [SEED, ]}\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('lr', LogisticRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=grid,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "lr_models = dict()\n",
    "\n",
    "for model_name in embedding_models:\n",
    "    X_train = X_trains[model_name]\n",
    "    grid_search = grid_search.fit(X_train, y_train)\n",
    "    lr_models[model_name] = grid_search.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:05:13.782945793Z",
     "start_time": "2023-10-14T15:05:13.735444850Z"
    }
   },
   "id": "fe0a3b8e9c42a059"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbow\n"
     ]
    },
    {
     "data": {
      "text/plain": "              precision    recall  f1-score  support\n0              0.833333  1.000000  0.909091      500\n1              0.000000  0.000000  0.000000      100\naccuracy            NaN       NaN  0.833333      600\nmacro avg      0.416667  0.500000  0.454545      600\nweighted avg   0.694444  0.833333  0.757576      600",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n      <th>support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.833333</td>\n      <td>1.000000</td>\n      <td>0.909091</td>\n      <td>500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>accuracy</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.833333</td>\n      <td>600</td>\n    </tr>\n    <tr>\n      <th>macro avg</th>\n      <td>0.416667</td>\n      <td>0.500000</td>\n      <td>0.454545</td>\n      <td>600</td>\n    </tr>\n    <tr>\n      <th>weighted avg</th>\n      <td>0.694444</td>\n      <td>0.833333</td>\n      <td>0.757576</td>\n      <td>600</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "array([[500,   0],\n       [100,   0]])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "skipgram\n"
     ]
    },
    {
     "data": {
      "text/plain": "              precision  recall  f1-score  support\n0              0.954198    1.00  0.976562      500\n1              1.000000    0.76  0.863636      100\naccuracy            NaN     NaN  0.960000      600\nmacro avg      0.977099    0.88  0.920099      600\nweighted avg   0.961832    0.96  0.957741      600",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n      <th>support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.954198</td>\n      <td>1.00</td>\n      <td>0.976562</td>\n      <td>500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.000000</td>\n      <td>0.76</td>\n      <td>0.863636</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>accuracy</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.960000</td>\n      <td>600</td>\n    </tr>\n    <tr>\n      <th>macro avg</th>\n      <td>0.977099</td>\n      <td>0.88</td>\n      <td>0.920099</td>\n      <td>600</td>\n    </tr>\n    <tr>\n      <th>weighted avg</th>\n      <td>0.961832</td>\n      <td>0.96</td>\n      <td>0.957741</td>\n      <td>600</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "array([[500,   0],\n       [ 24,  76]])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "fasttext\n"
     ]
    },
    {
     "data": {
      "text/plain": "              precision    recall  f1-score  support\n0              0.982249  0.996000  0.989076      500\n1              0.978495  0.910000  0.943005      100\naccuracy            NaN       NaN  0.981667      600\nmacro avg      0.980372  0.953000  0.966041      600\nweighted avg   0.981623  0.981667  0.981398      600",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n      <th>support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.982249</td>\n      <td>0.996000</td>\n      <td>0.989076</td>\n      <td>500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.978495</td>\n      <td>0.910000</td>\n      <td>0.943005</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>accuracy</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.981667</td>\n      <td>600</td>\n    </tr>\n    <tr>\n      <th>macro avg</th>\n      <td>0.980372</td>\n      <td>0.953000</td>\n      <td>0.966041</td>\n      <td>600</td>\n    </tr>\n    <tr>\n      <th>weighted avg</th>\n      <td>0.981623</td>\n      <td>0.981667</td>\n      <td>0.981398</td>\n      <td>600</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "array([[498,   2],\n       [  9,  91]])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "for estimator_name in lr_models:\n",
    "    X_test = X_tests[estimator_name]\n",
    "    print(estimator_name)\n",
    "    y_pred = lr_models[estimator_name].predict(X_test)\n",
    "    display(classification_report_pd(y_test, y_pred))\n",
    "    display(confusion_matrix(y_test, y_pred))\n",
    "    print('=============================================')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T15:03:09.187827948Z",
     "start_time": "2023-10-14T15:03:09.010731201Z"
    }
   },
   "id": "fd995f753e74eca9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Очень интересно и странно, изначально, когда я решил отказаться от идеи с классификацией постов с ленты, получалось примерно то же самое, все классифицировалось в один класс. В данном случае, с fastText получилось исправить ситуацию, но не с cbow/skipgram. \n",
    "\n",
    "При этом, skipgram относительно cbow хотя бы что-то обнаружил, то есть я был прав, когда говорил про то, что skipgram лучше. \n",
    "\n",
    "Не знаю, как сделать так, чтобы и они работали. Но в результате, получился достаточно хороший классификатор (последний).\n",
    "\n",
    "  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88ddf455d4313f29"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
