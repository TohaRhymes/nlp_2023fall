{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Задание 5 - 20 баллов\n",
    "\n",
    "- Загрузить набор данных Lenta.ru с помощью пакета Corus\n",
    "- Обучить LDA модель, постараться подобрать адекватные параметры (num_topics, passes, alpha, iterations…) - **4 балла**\n",
    "- Визуализировать результаты работы LDA с помощью pyLDAvis - **2 балла**\n",
    "- Посчитать внутренние метрики обученных моделей LDA (с разными параметрами) и сравнить, соответствует ли метрика визуальному качеству работы моделей - **2 балла**\n",
    "- Обучить модель BigARTM, использовать не менее двух регуляризаторов, оценить качество с помощью метрик - **5 баллов**\n",
    "- Реализовать визуализацию топиков BigARTM через pyLDAvis - **4 балла**\n",
    "\n",
    "- Обеспечена воспроизводимость решения: зафиксированы random_state, ноутбук воспроизводится от начала до конца без ошибок - **2 балла**\n",
    "\n",
    "- Соблюден code style на уровне pep8 и [On writing clean Jupyter notebooks](https://ploomber.io/blog/clean-nbs/)  - **1 балл**\n",
    "\n",
    "Примечание: подбирать параметры теметической модели можно также, как и для любой другой модели - на кроссвалидации, ориентируясь на метрики качества"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1150d329e479fe0d"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "from corus import load_lenta\n",
    "import os\n",
    "import gensim\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import demoji\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gensim import corpora\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.colors as mcolors\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "import warnings, logging\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "NLP = spacy.load(\"ru_core_news_sm\")\n",
    "CHECK_POS = {'PUNCT', 'ADP', 'AUX', 'CCONJ', 'SCONJ'}\n",
    "PATTERN_EMAIL = r'([A-Za-z0-9]+[.-_])*[A-Za-z0-9]+@[A-Za-z0-9-]+(\\.[A-Z|a-z]{2,})+'\n",
    "\n",
    "SEED = 566\n",
    "# data dir\n",
    "DATA_DIR = \"../data\"\n",
    "# path to the data\n",
    "DATA_PATH = os.path.join(DATA_DIR, \"lenta-ru-news.csv.gz\")\n",
    "# amount of texts to work with\n",
    "N_TEXTS = 500"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T22:16:45.532735711Z",
     "start_time": "2023-11-01T22:16:44.768209544Z"
    }
   },
   "id": "b1d6957efaa6bb00"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Загрузка текста"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cec9d79915d6b6b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Загрузим данные в директорию `../data/`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7df7d0f7405a2572"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# ! wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
    "# ! mv lenta-ru-news.csv.gz ../data/"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T21:58:25.246488579Z",
     "start_time": "2023-11-01T21:58:25.200796843Z"
    }
   },
   "id": "fdfeed18d60b1cc6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Читаем датасет"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b518cf601a7db7d7"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "LentaRecord(\n    url='https://lenta.ru/news/2018/12/14/cancer/',\n    title='Названы регионы России с\\xa0самой высокой смертностью от\\xa0рака',\n    text='Вице-премьер по социальным вопросам Татьяна Голикова рассказала, в каких регионах России зафиксирована наиболее высокая смертность от рака, сообщает РИА Новости. По словам Голиковой, чаще всего онкологические заболевания становились причиной смерти в Псковской, Тверской, Тульской и Орловской областях, а также в Севастополе. Вице-премьер напомнила, что главные факторы смертности в России — рак и болезни системы кровообращения. В начале года стало известно, что смертность от онкологических заболеваний среди россиян снизилась впервые за три года. По данным Росстата, в 2017 году от рака умерли 289 тысяч человек. Это на 3,5 процента меньше, чем годом ранее.',\n    topic='Россия',\n    tags='Общество',\n    date=None\n)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = load_lenta(DATA_PATH)\n",
    "next(records)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T21:58:25.930025283Z",
     "start_time": "2023-11-01T21:58:25.903909737Z"
    }
   },
   "id": "ed7a638e3f508ab6"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "('Австрийские правоохранительные органы не представили доказательств нарушения российскими биатлонистами антидопинговых правил. Об этом сообщил посол России в Вене Дмитрий Любинский по итогам встречи уполномоченного адвоката дипмиссии с представителями прокуратуры страны, передает ТАСС. «Действует презумпция невиновности. Каких-либо ограничений свободы передвижения для команды нет», — добавили в посольстве. Международный союз биатлонистов (IBU) также не будет применять санкции к российским биатлонистам. Все они продолжат выступление на Кубке мира. Полиция нагрянула в отель сборной России в Хохфильцене вечером 12 декабря. Как написал биатлонист Александр Логинов, их считают виновными в махинациях с переливанием крови. Биатлонисту Антону Шипулину, также попавшему в список, полиция нанесла отдельный визит: сейчас он тренируется отдельно в австрийском Обертиллахе. Обвинения спортсмен назвал бредом, а также указал на «охоту на ведьм» в мировом биатлоне. В Австрии прием допинга — уголовное преступление. Максимальное наказание за его употребление — три года тюрьмы.',\n 'Спорт')"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_text_topics = [next(records) for i in range(N_TEXTS)]\n",
    "dataset = [tt.text for tt in dataset_text_topics]\n",
    "target = [tt.topic for tt in dataset_text_topics]\n",
    "dataset[0], target[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T21:58:26.552617180Z",
     "start_time": "2023-11-01T21:58:26.518150786Z"
    }
   },
   "id": "3e2895a458d0597a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Предобработка"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d05b8f631e811115"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def normalize_text(text: str) -> str:\n",
    "    checked_text = demoji.replace(text)\n",
    "    checked_text = re.sub(PATTERN_EMAIL, '<EMAIL>', checked_text)\n",
    "    return checked_text\n",
    "\n",
    "\n",
    "def normalize_data(text_data: List[str]) -> List[str]:\n",
    "    return list(map(normalize_text, text_data))\n",
    "\n",
    "\n",
    "def tokenize_clean_stem(text: str) -> List[str]:\n",
    "    text_NLPed = NLP(text)\n",
    "    return [token.lemma_ for token in text_NLPed\n",
    "            if token.pos_ not in CHECK_POS and not token.is_stop]\n",
    "\n",
    "\n",
    "def tokenize_clean_stem_data(text_data: List[str]) -> List[List[str]]:\n",
    "    return list(map(tokenize_clean_stem, text_data))\n",
    "\n",
    "\n",
    "def pipeline_preprocessing(text_data: List[str]) -> List[List[str]]:\n",
    "    data = normalize_data(text_data)\n",
    "    return tokenize_clean_stem_data(data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T21:58:27.865063096Z",
     "start_time": "2023-11-01T21:58:27.830867004Z"
    }
   },
   "id": "ae37c323f31b239b"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.6 s, sys: 26.8 ms, total: 27.6 s\n",
      "Wall time: 27.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preprocessed_dataset = pipeline_preprocessing(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T21:58:56.089007061Z",
     "start_time": "2023-11-01T21:58:28.413610392Z"
    }
   },
   "id": "a46ca8583a39ebaf"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(['австрийский',\n  'правоохранительный',\n  'орган',\n  'представить',\n  'доказательство',\n  'нарушение',\n  'российский',\n  'биатлонист',\n  'антидопинговый',\n  'правило'],\n 100)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_dataset[0][:10], len(preprocessed_dataset[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T21:58:56.109274129Z",
     "start_time": "2023-11-01T21:58:56.080257358Z"
    }
   },
   "id": "a59f833f189387f0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Получение N-grams\n",
    "\n",
    "`Automatically detect common phrases – aka multi-word expressions, word n-gram collocations – from a stream of sentences.`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fecc3f45a1ce57d"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def get_ngrams(texts_out, bigram_mod, trigram_mod):\n",
    "    texts_out = [bigram_mod[doc] for doc in texts_out]\n",
    "    texts_out = [trigram_mod[bigram_mod[doc]] for doc in texts_out]\n",
    "    return texts_out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T21:58:56.111433740Z",
     "start_time": "2023-11-01T21:58:56.084695064Z"
    }
   },
   "id": "4c93e2bae391969d"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(['австрийский',\n  'правоохранительный_орган',\n  'представить',\n  'доказательство',\n  'нарушение'],\n ['ценность', 'распространять', 'интернет', 'социальный_сеть', 'инициатива'])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram = gensim.models.Phrases(preprocessed_dataset, min_count=5, threshold=100)  # higher threshold fewer phrases.\n",
    "bigram[preprocessed_dataset][0][:5], bigram[preprocessed_dataset][5][5:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T21:58:56.207914765Z",
     "start_time": "2023-11-01T21:58:56.114394568Z"
    }
   },
   "id": "7ce64179aa5d7935"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Некоторы фразочки объединились, и в целом звучат логично: 'правоохранительный_орган', 'социальный_сеть'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30bad401c5b5dee1"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "['австрийский',\n 'правоохранительный_орган',\n 'представить',\n 'доказательство',\n 'нарушение',\n 'российский',\n 'биатлонист',\n 'антидопинговый_правило',\n 'сообщить',\n 'посол']"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram = gensim.models.Phrases(bigram[preprocessed_dataset], threshold=100)\n",
    "# make Phraser == FrozenPhrases\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "tokenized_dataset = get_ngrams(preprocessed_dataset, bigram_mod, trigram_mod)\n",
    "tokenized_dataset[0][:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T21:58:56.538247582Z",
     "start_time": "2023-11-01T21:58:56.203993608Z"
    }
   },
   "id": "2193a17eecf5e050"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "московский_патриархат_упц_мп\n",
      "заговор_цель_ведение_деятельность\n",
      "московский_патриархат_упц_мп\n",
      "московский_патриархат_упц_мп\n",
      "московский_патриархат_упц_мп\n",
      "московский_патриархат_упц_мп\n",
      "московский_патриархат_упц_мп\n",
      "московский_патриархат_упц_мп\n",
      "московский_патриархат_упц_мп\n",
      "заговор_цель_ведение_деятельность\n",
      "релиз_поступить_редакция_ленты.ру\n"
     ]
    }
   ],
   "source": [
    "flag = 10\n",
    "for item in tokenized_dataset:\n",
    "    for token in item:\n",
    "        if token.count('_') > 2:\n",
    "            print(token)\n",
    "            flag -= 1\n",
    "    if flag < 0:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T21:58:56.552882863Z",
     "start_time": "2023-11-01T21:58:56.535250926Z"
    }
   },
   "id": "20f2bc8051eeb9a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Создание словаря\n",
    "\n",
    "В конце у нас: bag-of-words format = list of (token_id, token_count)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "784edfdbd7ef88e9"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "('ibu', 'антидопинговый_правило')"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word = corpora.Dictionary(tokenized_dataset)\n",
    "dict(id2word)[1], dict(id2word)[5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T21:58:56.617001350Z",
     "start_time": "2023-11-01T21:58:56.538502966Z"
    }
   },
   "id": "492f554af1b67e48"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "[(0, 1),\n (1, 1),\n (2, 2),\n (3, 1),\n (4, 1),\n (5, 1),\n (6, 1),\n (7, 1),\n (8, 3),\n (9, 1)]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [id2word.doc2bow(text) for text in tokenized_dataset]\n",
    "corpus[0][:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T21:58:56.670350860Z",
     "start_time": "2023-11-01T21:58:56.628993565Z"
    }
   },
   "id": "cfc40835d118a3a3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LDA модель"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71f49801c188df51"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [05:39, 14.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 32s, sys: 6.45 s, total: 5min 38s\n",
      "Wall time: 5min 39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nums_topics = [3, 5, 7]\n",
    "alphas = ['symmetric', 'asymmetric']  # A-priori belief on document-topic distribution\n",
    "passes = [25, 100]  # Number of passes through the corpus during training\n",
    "iterations = [25,\n",
    "              100]  # Maximum number of iterations through the corpus when inferring the topic distribution of a corpus\n",
    "\n",
    "params_sets = list(product(nums_topics, alphas, passes, iterations))\n",
    "param_names = ['num_topics', 'alpha', 'passes', 'iterations']\n",
    "\n",
    "coherence_scores = dict()\n",
    "perplexity_scores = dict()\n",
    "\n",
    "for num_topics, alpha, passes, iterations in tqdm(params_sets):\n",
    "\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=id2word,\n",
    "        num_topics=num_topics,\n",
    "        random_state=SEED,\n",
    "        update_every=1,  # Number of documents to be iterated through for each update\n",
    "        chunksize=10,  # == batch size\n",
    "        passes=passes,  # Number of passes through the corpus during training\n",
    "        alpha=alpha,  # A-priori belief on document-topic distribution\n",
    "        iterations=iterations,\n",
    "        # Maximum number of iterations through the corpus when inferring the topic distribution of a corpus,\n",
    "    )\n",
    "\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model,\n",
    "                                         texts=tokenized_dataset,\n",
    "                                         dictionary=id2word,\n",
    "                                         coherence='c_v')\n",
    "    coherence_score = coherence_model_lda.get_coherence()\n",
    "\n",
    "    perplexity_score = lda_model.log_perplexity(corpus)\n",
    "\n",
    "    coherence_scores[(num_topics, alpha, passes, iterations)] = coherence_score\n",
    "    perplexity_scores[(num_topics, alpha, passes, iterations)] = perplexity_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T22:16:44.768831371Z",
     "start_time": "2023-11-01T22:11:05.163020137Z"
    }
   },
   "id": "19d475082e389f0d"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0016068993276186954"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**perplexity_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T22:19:27.801324021Z",
     "start_time": "2023-11-01T22:19:27.783213686Z"
    }
   },
   "id": "35342b9ff5c258a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's look at scores"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1f514dcf50516fc"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "                       Params  Coherence  Log_Perplexity    Perplexity\n16     (7, symmetric, 25, 25)   0.371087       -9.474258  3.355381e-10\n18    (7, symmetric, 100, 25)   0.368366       -9.154316  7.009452e-10\n12    (5, asymmetric, 25, 25)   0.363092       -9.264435  5.439577e-10\n2     (3, symmetric, 100, 25)   0.357287       -8.864147  1.367267e-09\n10    (5, symmetric, 100, 25)   0.353174       -9.031985  9.289974e-10\n20    (7, asymmetric, 25, 25)   0.348206       -9.489662  3.238454e-10\n0      (3, symmetric, 25, 25)   0.347581       -9.029243  9.348818e-10\n6    (3, asymmetric, 100, 25)   0.342348       -8.869061  1.351881e-09\n4     (3, asymmetric, 25, 25)   0.338784       -9.025110  9.438222e-10\n8      (5, symmetric, 25, 25)   0.338635       -9.257704  5.524537e-10\n22   (7, asymmetric, 100, 25)   0.331440       -9.172154  6.727376e-10\n14   (5, asymmetric, 100, 25)   0.329763       -9.039595  9.128613e-10\n3    (3, symmetric, 100, 100)   0.316216       -8.865910  1.361726e-09\n1     (3, symmetric, 25, 100)   0.312646       -9.020780  9.532784e-10\n7   (3, asymmetric, 100, 100)   0.310392       -8.864684  1.365577e-09\n5    (3, asymmetric, 25, 100)   0.307387       -9.016936  9.617537e-10\n19   (7, symmetric, 100, 100)   0.304645       -9.270146  5.368513e-10\n17    (7, symmetric, 25, 100)   0.301939       -9.584368  2.603945e-10\n9     (5, symmetric, 25, 100)   0.297601       -9.292039  5.104590e-10\n23  (7, asymmetric, 100, 100)   0.290919       -9.281505  5.229923e-10\n13   (5, asymmetric, 25, 100)   0.290274       -9.294782  5.072454e-10\n11   (5, symmetric, 100, 100)   0.289362       -9.068186  8.547014e-10\n15  (5, asymmetric, 100, 100)   0.286419       -9.067466  8.561179e-10\n21   (7, asymmetric, 25, 100)   0.285108       -9.591795  2.559796e-10",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Params</th>\n      <th>Coherence</th>\n      <th>Log_Perplexity</th>\n      <th>Perplexity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>16</th>\n      <td>(7, symmetric, 25, 25)</td>\n      <td>0.371087</td>\n      <td>-9.474258</td>\n      <td>3.355381e-10</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>(7, symmetric, 100, 25)</td>\n      <td>0.368366</td>\n      <td>-9.154316</td>\n      <td>7.009452e-10</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>(5, asymmetric, 25, 25)</td>\n      <td>0.363092</td>\n      <td>-9.264435</td>\n      <td>5.439577e-10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(3, symmetric, 100, 25)</td>\n      <td>0.357287</td>\n      <td>-8.864147</td>\n      <td>1.367267e-09</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>(5, symmetric, 100, 25)</td>\n      <td>0.353174</td>\n      <td>-9.031985</td>\n      <td>9.289974e-10</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>(7, asymmetric, 25, 25)</td>\n      <td>0.348206</td>\n      <td>-9.489662</td>\n      <td>3.238454e-10</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>(3, symmetric, 25, 25)</td>\n      <td>0.347581</td>\n      <td>-9.029243</td>\n      <td>9.348818e-10</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>(3, asymmetric, 100, 25)</td>\n      <td>0.342348</td>\n      <td>-8.869061</td>\n      <td>1.351881e-09</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(3, asymmetric, 25, 25)</td>\n      <td>0.338784</td>\n      <td>-9.025110</td>\n      <td>9.438222e-10</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>(5, symmetric, 25, 25)</td>\n      <td>0.338635</td>\n      <td>-9.257704</td>\n      <td>5.524537e-10</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>(7, asymmetric, 100, 25)</td>\n      <td>0.331440</td>\n      <td>-9.172154</td>\n      <td>6.727376e-10</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>(5, asymmetric, 100, 25)</td>\n      <td>0.329763</td>\n      <td>-9.039595</td>\n      <td>9.128613e-10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(3, symmetric, 100, 100)</td>\n      <td>0.316216</td>\n      <td>-8.865910</td>\n      <td>1.361726e-09</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(3, symmetric, 25, 100)</td>\n      <td>0.312646</td>\n      <td>-9.020780</td>\n      <td>9.532784e-10</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>(3, asymmetric, 100, 100)</td>\n      <td>0.310392</td>\n      <td>-8.864684</td>\n      <td>1.365577e-09</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>(3, asymmetric, 25, 100)</td>\n      <td>0.307387</td>\n      <td>-9.016936</td>\n      <td>9.617537e-10</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>(7, symmetric, 100, 100)</td>\n      <td>0.304645</td>\n      <td>-9.270146</td>\n      <td>5.368513e-10</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>(7, symmetric, 25, 100)</td>\n      <td>0.301939</td>\n      <td>-9.584368</td>\n      <td>2.603945e-10</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>(5, symmetric, 25, 100)</td>\n      <td>0.297601</td>\n      <td>-9.292039</td>\n      <td>5.104590e-10</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>(7, asymmetric, 100, 100)</td>\n      <td>0.290919</td>\n      <td>-9.281505</td>\n      <td>5.229923e-10</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>(5, asymmetric, 25, 100)</td>\n      <td>0.290274</td>\n      <td>-9.294782</td>\n      <td>5.072454e-10</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>(5, symmetric, 100, 100)</td>\n      <td>0.289362</td>\n      <td>-9.068186</td>\n      <td>8.547014e-10</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>(5, asymmetric, 100, 100)</td>\n      <td>0.286419</td>\n      <td>-9.067466</td>\n      <td>8.561179e-10</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>(7, asymmetric, 25, 100)</td>\n      <td>0.285108</td>\n      <td>-9.591795</td>\n      <td>2.559796e-10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_coherence = pd.DataFrame(list(coherence_scores.items()), columns=['Params', 'Coherence'])\n",
    "df_perplexity = pd.DataFrame(list(perplexity_scores.items()), columns=['Params', 'Log_Perplexity'])\n",
    "df = pd.merge(df_coherence, df_perplexity, on='Params', how='outer')\n",
    "df['Perplexity'] = df['Log_Perplexity'].apply(lambda x: 10**x)\n",
    "df_sorted = df.sort_values(by=['Coherence'], ascending=[False], na_position='last')\n",
    "display(df_sorted)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T22:23:23.184942896Z",
     "start_time": "2023-11-01T22:23:23.136306263Z"
    }
   },
   "id": "c9ccba79ad8761bb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Перплексия везде маленькая, и примерно одинаковая (как и когерентность). Возьмем по когерентности лучшую модель."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43a60618837c95fe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
